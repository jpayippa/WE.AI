{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b0e9c6c",
   "metadata": {},
   "source": [
    "# Fine-Tuning Mistral 7B with RAG on Vertex AI Workbench\n",
    "This notebook prepares, fine-tunes, and saves a Mistral 7B model using QLoRA on a T4 GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ad7977e-35f5-472c-92e6-358c60501c02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.16\n"
     ]
    }
   ],
   "source": [
    "!python --version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "094ed7f1-39fe-463e-ab53-87545ef89f5c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in /opt/conda/envs/pytorch/lib/python3.10/site-packages (1.13.1)\n",
      "Requirement already satisfied: torchvision in /opt/conda/envs/pytorch/lib/python3.10/site-packages (0.14.1)\n",
      "Collecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (75.8.0)\n",
      "Requirement already satisfied: wheel in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.45.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torchvision) (2.32.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torchvision) (11.1.0)\n",
      "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.5.0%2Bcu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m145.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.4.1%2Bcu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m149.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.4.0%2Bcu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.3.1%2Bcu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m153.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.3.0%2Bcu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m148.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.2.2%2Bcu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m150.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.2.1%2Bcu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m147.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is still looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.2.0%2Bcu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.1.2%2Bcu121-cp310-cp310-linux_x86_64.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m137.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.1.1%2Bcu121-cp310-cp310-linux_x86_64.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m131.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.1.0%2Bcu121-cp310-cp310-linux_x86_64.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp310-cp310-linux_x86_64.whl (7.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m165.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp310-cp310-linux_x86_64.whl (780.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.4/780.4 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch) (2025.2.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m146.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m108.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m120.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m106.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m96.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m102.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Collecting triton==3.1.0 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m104.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting sympy==1.13.1 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m159.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvjitlink_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (19.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m182.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Installing collected packages: mpmath, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.13.1\n",
      "    Uninstalling torch-1.13.1:\n",
      "      Successfully uninstalled torch-1.13.1\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/envs/pytorch/lib/python3.10/site-packages/~orch'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.14.1\n",
      "    Uninstalling torchvision-0.14.1:\n",
      "      Successfully uninstalled torchvision-0.14.1\n",
      "Successfully installed mpmath-1.3.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.1.105 nvidia-nvtx-cu12-12.1.105 sympy-1.13.1 torch-2.5.1+cu121 torchaudio-2.5.1+cu121 torchvision-0.20.1+cu121 triton-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1de367b-94d5-4637-98ef-822345b632fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting datasets\n",
      "  Using cached datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting peft\n",
      "  Using cached peft-0.14.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting accelerate\n",
      "  Using cached accelerate-1.4.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: scipy in /opt/conda/envs/pytorch/lib/python3.10/site-packages (1.15.1)\n",
      "Collecting jupyter\n",
      "  Downloading jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from transformers) (3.17.0)\n",
      "Collecting huggingface-hub<1.0,>=0.26.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.29.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Using cached regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Using cached tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from datasets) (15.0.2)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from datasets) (2.2.3)\n",
      "Collecting xxhash (from datasets)\n",
      "  Using cached xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Using cached multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
      "  Using cached fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from datasets) (3.11.12)\n",
      "Requirement already satisfied: psutil in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from peft) (5.9.3)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from peft) (2.5.1+cu121)\n",
      "Requirement already satisfied: notebook in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyter) (6.5.7)\n",
      "Collecting jupyter-console (from jupyter)\n",
      "  Downloading jupyter_console-6.6.3-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyter) (7.16.6)\n",
      "Requirement already satisfied: ipykernel in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyter) (6.29.5)\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyter) (8.1.5)\n",
      "Requirement already satisfied: jupyterlab in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyter) (3.6.8)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp->datasets) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests->transformers) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests->transformers) (2024.12.14)\n",
      "Requirement already satisfied: networkx in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.5)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch>=1.13.0->peft) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch>=1.13.0->peft) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch>=1.13.0->peft) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: triton==3.1.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ipykernel->jupyter) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ipykernel->jupyter) (1.8.12)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ipykernel->jupyter) (8.21.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ipykernel->jupyter) (7.4.9)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ipykernel->jupyter) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ipykernel->jupyter) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ipykernel->jupyter) (1.6.0)\n",
      "Requirement already satisfied: pyzmq>=24 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ipykernel->jupyter) (26.2.1)\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ipykernel->jupyter) (6.4.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ipykernel->jupyter) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ipywidgets->jupyter) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ipywidgets->jupyter) (3.0.13)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.30 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyter-console->jupyter) (3.0.50)\n",
      "Requirement already satisfied: pygments in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyter-console->jupyter) (2.19.1)\n",
      "Requirement already satisfied: jupyterlab-server~=2.19 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyterlab->jupyter) (2.27.3)\n",
      "Requirement already satisfied: jupyter-server<3,>=1.16.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyterlab->jupyter) (2.15.0)\n",
      "Requirement already satisfied: jupyter-ydoc~=0.2.4 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyterlab->jupyter) (0.2.5)\n",
      "Requirement already satisfied: jupyter-server-ydoc~=0.8.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyterlab->jupyter) (0.8.0)\n",
      "Requirement already satisfied: nbclassic in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyterlab->jupyter) (1.2.0)\n",
      "Requirement already satisfied: tomli in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyterlab->jupyter) (2.2.1)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from notebook->jupyter) (23.1.0)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from notebook->jupyter) (0.2.0)\n",
      "Requirement already satisfied: nbformat in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from notebook->jupyter) (5.10.4)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from notebook->jupyter) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from notebook->jupyter) (0.18.1)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from notebook->jupyter) (0.21.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from nbconvert->jupyter) (4.13.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from nbconvert->jupyter) (0.3.0)\n",
      "Requirement already satisfied: markupsafe>=2.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from nbconvert->jupyter) (3.0.2)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from nbconvert->jupyter) (3.1.1)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from nbconvert->jupyter) (0.10.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from nbconvert->jupyter) (1.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: webencodings in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter) (1.4.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.19.2)\n",
      "Requirement already satisfied: stack-data in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.6.3)\n",
      "Requirement already satisfied: exceptiongroup in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (1.2.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (4.9.0)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (0.4)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (4.3.6)\n",
      "Requirement already satisfied: anyio>=3.1.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyter-server<3,>=1.16.0->jupyterlab->jupyter) (4.8.0)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyter-server<3,>=1.16.0->jupyterlab->jupyter) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyter-server<3,>=1.16.0->jupyterlab->jupyter) (0.5.3)\n",
      "Requirement already satisfied: overrides>=5.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyter-server<3,>=1.16.0->jupyterlab->jupyter) (7.7.0)\n",
      "Requirement already satisfied: websocket-client>=1.7 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyter-server<3,>=1.16.0->jupyterlab->jupyter) (1.8.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from argon2-cffi->notebook->jupyter) (21.2.0)\n",
      "Requirement already satisfied: jupyter-server-fileid<1,>=0.6.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyter-server-ydoc~=0.8.0->jupyterlab->jupyter) (0.9.3)\n",
      "Requirement already satisfied: ypy-websocket<0.9.0,>=0.8.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyter-server-ydoc~=0.8.0->jupyterlab->jupyter) (0.8.4)\n",
      "Requirement already satisfied: y-py<0.7.0,>=0.6.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyter-ydoc~=0.2.4->jupyterlab->jupyter) (0.6.2)\n",
      "Requirement already satisfied: babel>=2.10 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyterlab-server~=2.19->jupyterlab->jupyter) (2.17.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyterlab-server~=2.19->jupyterlab->jupyter) (0.10.0)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyterlab-server~=2.19->jupyterlab->jupyter) (4.23.0)\n",
      "Requirement already satisfied: notebook-shim>=0.2.3 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from nbclassic->jupyterlab->jupyter) (0.2.4)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from nbformat->notebook->jupyter) (2.21.1)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: ptyprocess in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from terminado>=0.8.3->notebook->jupyter) (0.7.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from beautifulsoup4->nbconvert->jupyter) (2.5)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server<3,>=1.16.0->jupyterlab->jupyter) (1.3.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter) (0.8.4)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server~=2.19->jupyterlab->jupyter) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server~=2.19->jupyterlab->jupyter) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server~=2.19->jupyterlab->jupyter) (0.22.3)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=1.16.0->jupyterlab->jupyter) (2.0.7)\n",
      "Requirement already satisfied: rfc3339-validator in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=1.16.0->jupyterlab->jupyter) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=1.16.0->jupyterlab->jupyter) (0.1.1)\n",
      "Requirement already satisfied: aiofiles<23,>=22.1.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ypy-websocket<0.9.0,>=0.8.2->jupyter-server-ydoc~=0.8.0->jupyterlab->jupyter) (22.1.0)\n",
      "Requirement already satisfied: aiosqlite<1,>=0.17.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ypy-websocket<0.9.0,>=0.8.2->jupyter-server-ydoc~=0.8.0->jupyterlab->jupyter) (0.21.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter) (1.17.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter) (0.2.3)\n",
      "Requirement already satisfied: pycparser in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter) (2.22)\n",
      "Requirement already satisfied: fqdn in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=1.16.0->jupyterlab->jupyter) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=1.16.0->jupyterlab->jupyter) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=1.16.0->jupyterlab->jupyter) (3.0.0)\n",
      "Requirement already satisfied: uri-template in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=1.16.0->jupyterlab->jupyter) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=1.16.0->jupyterlab->jupyter) (24.11.1)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=1.16.0->jupyterlab->jupyter) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=1.16.0->jupyterlab->jupyter) (2.9.0.20241206)\n",
      "Using cached transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
      "Using cached datasets-3.3.2-py3-none-any.whl (485 kB)\n",
      "Using cached peft-0.14.0-py3-none-any.whl (374 kB)\n",
      "Using cached accelerate-1.4.0-py3-none-any.whl (342 kB)\n",
      "Downloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "Downloading huggingface_hub-0.29.3-py3-none-any.whl (468 kB)\n",
      "Using cached multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Using cached regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Using cached tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "Downloading jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
      "Using cached xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Installing collected packages: xxhash, safetensors, regex, fsspec, dill, multiprocess, huggingface-hub, tokenizers, transformers, jupyter-console, bitsandbytes, accelerate, peft, datasets, jupyter\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.2.0\n",
      "    Uninstalling fsspec-2025.2.0:\n",
      "      Successfully uninstalled fsspec-2025.2.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2025.2.0 requires fsspec==2025.2.0, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed accelerate-1.4.0 bitsandbytes-0.45.3 datasets-3.3.2 dill-0.3.8 fsspec-2024.12.0 huggingface-hub-0.29.3 jupyter-1.1.1 jupyter-console-6.6.3 multiprocess-0.70.16 peft-0.14.0 regex-2024.11.6 safetensors-0.5.3 tokenizers-0.21.0 transformers-4.49.0 xxhash-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets peft accelerate bitsandbytes scipy jupyter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ae29fd0-3661-4367-bc9c-caa1092f957f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Version: 2.5.1+cu121\n",
      "CUDA Available: True\n",
      "Transformers Version: 4.49.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "\n",
    "print(\"Torch Version:\", torch.__version__)\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"Transformers Version:\", transformers.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbf034ff-002c-41b5-8718-26ee0686914c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fsspec==2025.2.0\n",
      "  Downloading fsspec-2025.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Downloading fsspec-2025.2.0-py3-none-any.whl (184 kB)\n",
      "Installing collected packages: fsspec\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.12.0\n",
      "    Uninstalling fsspec-2024.12.0:\n",
      "      Successfully uninstalled fsspec-2024.12.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 3.3.2 requires fsspec[http]<=2024.12.0,>=2023.1.0, but you have fsspec 2025.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed fsspec-2025.2.0\n",
      "Requirement already satisfied: gcsfs==2025.2.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (2025.2.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from gcsfs==2025.2.0) (3.11.12)\n",
      "Requirement already satisfied: decorator>4.1.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from gcsfs==2025.2.0) (5.1.1)\n",
      "Requirement already satisfied: fsspec==2025.2.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from gcsfs==2025.2.0) (2025.2.0)\n",
      "Requirement already satisfied: google-auth>=1.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from gcsfs==2025.2.0) (2.38.0)\n",
      "Requirement already satisfied: google-auth-oauthlib in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from gcsfs==2025.2.0) (1.2.1)\n",
      "Requirement already satisfied: google-cloud-storage in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from gcsfs==2025.2.0) (2.14.0)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from gcsfs==2025.2.0) (2.32.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs==2025.2.0) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs==2025.2.0) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs==2025.2.0) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs==2025.2.0) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs==2025.2.0) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs==2025.2.0) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs==2025.2.0) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs==2025.2.0) (1.18.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from google-auth>=1.2->gcsfs==2025.2.0) (5.5.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from google-auth>=1.2->gcsfs==2025.2.0) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from google-auth>=1.2->gcsfs==2025.2.0) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from google-auth-oauthlib->gcsfs==2025.2.0) (2.0.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from google-cloud-storage->gcsfs==2025.2.0) (1.34.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from google-cloud-storage->gcsfs==2025.2.0) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media>=2.6.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from google-cloud-storage->gcsfs==2025.2.0) (2.7.2)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from google-cloud-storage->gcsfs==2025.2.0) (1.6.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests->gcsfs==2025.2.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests->gcsfs==2025.2.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests->gcsfs==2025.2.0) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests->gcsfs==2025.2.0) (2024.12.14)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage->gcsfs==2025.2.0) (1.67.0rc1)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage->gcsfs==2025.2.0) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from multidict<7.0,>=4.5->aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs==2025.2.0) (4.12.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs==2025.2.0) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs==2025.2.0) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install fsspec==2025.2.0 --no-cache-dir\n",
    "!pip install gcsfs==2025.2.0 --no-cache-dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "029f93a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:All required packages installed and imported successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Install necessary dependencies\n",
    "!pip install torch transformers datasets accelerate peft bitsandbytes sentencepiece google-cloud-aiplatform --quiet\n",
    "\n",
    "import torch\n",
    "import logging\n",
    "import json\n",
    "import random\n",
    "from datasets import Dataset\n",
    "from transformers import (AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer,\n",
    "                          BitsAndBytesConfig)\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "# Enable logging for debugging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logger.info(\"All required packages installed and imported successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dc67103-cb06-4f9b-9ab1-39c7f832a2ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: /home/jupyter\n",
      "Files in directory: ['.jupyter', 'mistral_finetune_vertexai_WEAI.ipynb', '.config', 'mistral-weai-finetune', '.bash_history', '.gsutil', '.ipython', 'transformed_dataset.jsonl', 'logs', '.nv', '.triton', 'RAG', 'mistral-weai-finetuned.zip', 'mistral-finetuned', 'mistral-weai-finetuned', '.ipynb_checkpoints', '.local', '.cache', '.docker', 'weai_finetune_data.jsonl', '.bashrc', '.npm']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Print current working directory\n",
    "print(\"Current Directory:\", os.getcwd())\n",
    "\n",
    "# List all files in the directory\n",
    "print(\"Files in directory:\", os.listdir())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c5c3c94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading dataset from transformed_dataset.jsonl\n",
      "INFO:__main__:Loaded 4068 samples.\n",
      "INFO:__main__:Training samples: 3254, Validation samples: 814\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load dataset\n",
    "dataset_path = \"transformed_dataset.jsonl\"  # Adjust path if needed\n",
    "logger.info(f\"Loading dataset from {dataset_path}\")\n",
    "\n",
    "try:\n",
    "    with open(dataset_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = [json.loads(line) for line in f]\n",
    "    logger.info(f\"Loaded {len(data)} samples.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to load dataset: {e}\")\n",
    "    raise e\n",
    "\n",
    "# Ensure dataset follows the required format for Mistral 7B with RAG\n",
    "for idx, sample in enumerate(data[:5]):\n",
    "    if \"messages\" not in sample or not isinstance(sample[\"messages\"], list):\n",
    "        logger.error(f\"Malformed sample at index {idx}: {sample}\")\n",
    "        raise ValueError(\"Dataset does not follow the expected Mistral RAG format.\")\n",
    "\n",
    "# Shuffle and split dataset (80% train, 20% validation)\n",
    "random.seed(42)\n",
    "random.shuffle(data)\n",
    "split_idx = int(len(data) * 0.8)\n",
    "train_dataset = Dataset.from_list(data[:split_idx])\n",
    "eval_dataset = Dataset.from_list(data[split_idx:])\n",
    "\n",
    "logger.info(f\"Training samples: {len(train_dataset)}, Validation samples: {len(eval_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61a508aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(\"xxxxxxxxxxxxxxxxxxxxxxxxxxxxx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baf964c5-2e51-442b-b401-d7aece90f80e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /opt/conda/envs/pytorch/lib/python3.10/site-packages (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b92be421-a17c-4101-b1db-aecfaaa3a778",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2.0\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece\n",
    "print(sentencepiece.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f1b87d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading tokenizer for mistralai/Mistral-7B-Instruct-v0.3\n",
      "INFO:__main__:Tokenizer loaded successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "# Load tokenizer\n",
    "model_name = 'mistralai/Mistral-7B-Instruct-v0.3'\n",
    "logger.info(f\"Loading tokenizer for {model_name}\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Set padding token\n",
    "\n",
    "print(\"Tokenizer loaded successfully!\")\n",
    "\n",
    "logger.info(\"Tokenizer loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8956fb25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Formatting function defined successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to format messages into a string for tokenization\n",
    "def formatting_func(example):\n",
    "    if \"messages\" not in example or not isinstance(example[\"messages\"], list):\n",
    "        raise ValueError(\"Each example must have a 'messages' list.\")\n",
    "    \n",
    "    for i, msg in enumerate(example[\"messages\"]):\n",
    "        if not isinstance(msg, dict) or \"role\" not in msg or \"content\" not in msg:\n",
    "            raise ValueError(f\"Invalid message structure at index {i}: {msg}\")\n",
    "    \n",
    "    formatted_text = tokenizer.apply_chat_template(conversation=example[\"messages\"])\n",
    "    return {\"text\": formatted_text}\n",
    "\n",
    "logger.info(\"Formatting function defined successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b83ef71-088f-4c9c-afc1-2f689fd8652b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{'messages': [{'content': 'You are an AI assistant for Western University, providing accurate university-related information. Only respond to topics directly related to Western University or Western Engineering. If the question is unrelated, politely decline to answer.', 'role': 'system'}, {'content': 'Can you tell me about 2020 Fall Award Recipients at Western University?', 'role': 'user'}, {'content': 'Spencer Engineering Building', 'role': 'assistant'}]}\n"
     ]
    }
   ],
   "source": [
    "print(type(train_dataset[0]))  # Should be <class 'dict'>\n",
    "print(train_dataset[0])  # Print first sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa16df37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_and_tokenize_prompt(examples):\n",
    "    \"\"\"\n",
    "    Function to format and tokenize dataset examples for Mistral 7B.\n",
    "    Ensures correct input formatting for tokenization.\n",
    "    \"\"\"\n",
    "    formatted_texts = []\n",
    "\n",
    "    for ex in examples[\"messages\"]:\n",
    "        if not isinstance(ex, list):\n",
    "            raise TypeError(f\"Expected a list of messages, but got {type(ex)}. Full data: {ex}\")\n",
    "\n",
    "        # Convert conversation into a single string using Hugging Face chat template\n",
    "        formatted_text = tokenizer.apply_chat_template(conversation=ex, tokenize=False)  # Set `tokenize=False` to return a string\n",
    "        formatted_texts.append(formatted_text)\n",
    "\n",
    "    if not formatted_texts or not all(isinstance(text, str) for text in formatted_texts):\n",
    "        raise ValueError(\"Formatted texts must be a list of strings.\")\n",
    "\n",
    "    # Tokenize formatted texts\n",
    "    tokenized_outputs = tokenizer(\n",
    "        formatted_texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    # Set labels (ignore padding tokens)\n",
    "    tokenized_outputs[\"labels\"] = [\n",
    "        [token_id if token_id != tokenizer.pad_token_id else -100 for token_id in output]\n",
    "        for output in tokenized_outputs[\"input_ids\"]\n",
    "    ]\n",
    "\n",
    "    return tokenized_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7af711e5-7b71-4dae-8e8f-3fde96fd055f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example before tokenization: {'messages': [{'content': 'You are an AI assistant for Western University, providing accurate university-related information. Only respond to topics directly related to Western University or Western Engineering. If the question is unrelated, politely decline to answer.', 'role': 'system'}, {'content': 'Can you tell me about 2020 Fall Award Recipients at Western University?', 'role': 'user'}, {'content': 'Spencer Engineering Building', 'role': 'assistant'}]}\n"
     ]
    }
   ],
   "source": [
    "print(\"Example before tokenization:\", train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5679ec27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Tokenizing training and validation datasets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dc3acb3771c47fbbe49ca60d08b4703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3254 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88baeda8ed834e8fa6e2f48676c6e1ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/814 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Tokenization completed successfully.\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Tokenizing training and validation datasets...\")\n",
    "\n",
    "try:\n",
    "    tokenized_train_dataset = train_dataset.map(\n",
    "        generate_and_tokenize_prompt,\n",
    "        batched=True,  \n",
    "        remove_columns=train_dataset.column_names\n",
    "    )\n",
    "\n",
    "    tokenized_val_dataset = eval_dataset.map(\n",
    "        generate_and_tokenize_prompt,\n",
    "        batched=True,\n",
    "        remove_columns=eval_dataset.column_names\n",
    "    )\n",
    "\n",
    "    logger.info(\"Tokenization completed successfully.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error in tokenization: {e}\")\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d020bd76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading model with 4-bit quantization...\n",
      "INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36d813878c9a4529818eb00124003932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load Mistral 7B model with 4-bit quantization for QLoRA\n",
    "logger.info(\"Loading model with 4-bit quantization...\")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "try:\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map='auto'\n",
    "    )\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id\n",
    "    logger.info(\"Model loaded successfully.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error loading model: {e}\")\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c924e45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Applying QLoRA configuration...\n",
      "INFO:__main__:QLoRA configuration applied successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Apply QLoRA with PEFT\n",
    "logger.info(\"Applying QLoRA configuration...\")\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    inference_mode=False,\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"down_proj\", \"up_proj\"]\n",
    ")\n",
    "\n",
    "try:\n",
    "    model = get_peft_model(model, peft_config)\n",
    "    logger.info(\"QLoRA configuration applied successfully.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error applying QLoRA: {e}\")\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1e8de5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Setting up training arguments...\n",
      "/opt/conda/envs/pytorch/lib/python3.10/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "INFO:__main__:Training arguments set successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define training arguments\n",
    "logger.info(\"Setting up training arguments...\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=8,\n",
    "    fp16=True,\n",
    "    optim='adamw_torch',\n",
    "    num_train_epochs=3,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    output_dir='./RAG/mistral-finetuned',\n",
    "    logging_steps=50,\n",
    "    logging_dir='./RAG/logs'\n",
    ")\n",
    "\n",
    "logger.info(\"Training arguments set successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed21f84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Starting training...\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1218' max='1218' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1218/1218 5:11:45, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.074600</td>\n",
       "      <td>1.347851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.781200</td>\n",
       "      <td>1.303357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Training completed successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize Trainer and start training\n",
    "logger.info(\"Starting training...\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset\n",
    ")\n",
    "\n",
    "try:\n",
    "    trainer.train()\n",
    "    logger.info(\"Training completed successfully.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Training failed: {e}\")\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66d7bd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Saving LoRA adapter weights to ./RAG/mistral-finetuned...\n",
      "INFO:__main__:LoRA adapters saved successfully.\n",
      "INFO:__main__:Saving the base Mistral 7B model to ./RAG/mistral-7b-base...\n",
      "INFO:__main__:Base model and LoRA adapters saved successfully.\n",
      "INFO:__main__:Zipping the entire './RAG' directory into mistral_rag_model.zip...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import logging\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Setup logger\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Define new paths inside the \"RAG\" directory\n",
    "output_dir = \"./RAG\"\n",
    "lora_model_path = os.path.join(output_dir, \"mistral-finetuned\")\n",
    "base_model_path = os.path.join(output_dir, \"mistral-7b-base\")\n",
    "zip_filename = \"mistral_rag_model.zip\"\n",
    "\n",
    "# Create the RAG directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save the LoRA adapter weights\n",
    "logger.info(f\"Saving LoRA adapter weights to {lora_model_path}...\")\n",
    "model.save_pretrained(lora_model_path)\n",
    "tokenizer.save_pretrained(lora_model_path)\n",
    "logger.info(\"LoRA adapters saved successfully.\")\n",
    "\n",
    "# Save the base Mistral 7B model (downloaded from Hugging Face)\n",
    "logger.info(f\"Saving the base Mistral 7B model to {base_model_path}...\")\n",
    "model.base_model.save_pretrained(base_model_path)  # Saves the full model\n",
    "\n",
    "# Copy the fine-tuned LoRA model into the base model folder for completeness\n",
    "shutil.copytree(lora_model_path, base_model_path, dirs_exist_ok=True)\n",
    "logger.info(\"Base model and LoRA adapters saved successfully.\")\n",
    "\n",
    "# ✅ ZIP the entire \"RAG\" directory\n",
    "zip_path = f\"./{zip_filename}\"\n",
    "logger.info(f\"Zipping the entire '{output_dir}' directory into {zip_filename}...\")\n",
    "shutil.make_archive(zip_filename.replace(\".zip\", \"\"), 'zip', output_dir)\n",
    "logger.info(f\"Model zipped successfully: {zip_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cf96fa-e223-46e5-a318-726d6aa44808",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ✅ Generate a Download Link\n",
    "logger.info(f\"Model archive is ready for download: {zip_path}\")\n",
    "FileLink(zip_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a88206-278a-4be1-953b-5a97882319b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from google.cloud import storage\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Define paths\n",
    "output_dir = \"./RAG\"\n",
    "zip_filename = \"mistral_finetuned.zip\"\n",
    "zip_filepath = f\"./{zip_filename}\"\n",
    "\n",
    "# Zip the entire \"RAG\" directory\n",
    "logger.info(f\"Zipping the model directory: {output_dir}...\")\n",
    "shutil.make_archive(zip_filepath.replace(\".zip\", \"\"), 'zip', output_dir)\n",
    "logger.info(f\"Model successfully zipped as {zip_filename}\")\n",
    "\n",
    "# Initialize Google Cloud Storage client\n",
    "storage_client = storage.Client()\n",
    "\n",
    "# Define GCS bucket names\n",
    "gcs_buckets = [\"we_ai_backup\", \"weai-finetune-1741723108\"]\n",
    "\n",
    "# Upload function\n",
    "def upload_to_gcs(bucket_name, source_file, destination_blob_name):\n",
    "    \"\"\"Uploads a file to a GCS bucket.\"\"\"\n",
    "    try:\n",
    "        bucket = storage_client.bucket(bucket_name)\n",
    "        blob = bucket.blob(destination_blob_name)\n",
    "        blob.upload_from_filename(source_file)\n",
    "        logger.info(f\"Uploaded {source_file} to gs://{bucket_name}/{destination_blob_name}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to upload to {bucket_name}: {e}\")\n",
    "\n",
    "# Upload zip file to both GCS buckets\n",
    "for bucket in gcs_buckets:\n",
    "    upload_to_gcs(bucket, zip_filepath, zip_filename)\n",
    "\n",
    "logger.info(\"Backup complete! Model zip file uploaded to both GCS buckets.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20a3dca-f439-481c-b6be-ab909a6e69b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-pytorch-pytorch",
   "name": "workbench-notebooks.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m128"
  },
  "kernelspec": {
   "display_name": "PyTorch 1-13 (Local)",
   "language": "python",
   "name": "conda-env-pytorch-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
